{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience # Load neo4j graph data science library\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if os.getcwd().split('\\\\')[-1] == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Modeling\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a Neo4j instance (assumes local right now)\n",
    "NEO4J_URI = os.environ.get(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_AUTH = None\n",
    "NEO4J_DB = os.environ.get(\"NEO4J_DB\", \"neo4j\")\n",
    "if os.environ.get(\"NEO4J_USER\") and os.environ.get(\"NEO4J_PASSWORD\"):\n",
    "    NEO4J_AUTH = (\n",
    "        os.environ.get(\"NEO4J_USER\"),\n",
    "        os.environ.get(\"NEO4J_PASSWORD\"),\n",
    "    )\n",
    "else:\n",
    "    NEO4J_AUTH = (\"neo4j\", \"Bookings\")\n",
    "gds = GraphDataScience(NEO4J_URI, auth=NEO4J_AUTH, database=NEO4J_DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the training data by finding positive and negative examples of bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:TRAIN_BOOKING]->(w:Week)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   1 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all properties that had did not have a booking in the current week, but had a booking in at least one of the previous two weeks\n",
    "negative_weeks_ahead = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:TRAIN_BOOKING]->()\n",
    "MATCH (p)-[:TRAIN_BOOKING]->(:Week)-[:PRECEDES*1..4]->(w)\n",
    "WHERE NOT (p)-[:TRAIN_BOOKING]->(w)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch the order of the relationship in the second match\n",
    "negative_weeks_behind = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:TRAIN_BOOKING]->()\n",
    "MATCH (p)-[:TRAIN_BOOKING]->(:Week)<-[:PRECEDES*1..4]-(w)\n",
    "WHERE NOT (p)-[:TRAIN_BOOKING]->(w)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties that were not booked on a given week where a totally different property was booked that week in the same city\n",
    "negative_same_city_diff_attrs = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:LOCATED_IN]->(c:City)\n",
    "MATCH (p)-[:HAS_TYPE]->(t:Type)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:TRAIN_BOOKING]->()\n",
    "MATCH (c)<-[:LOCATED_IN]-(p2:Property)-[:TRAIN_BOOKING]->(w)\n",
    "MATCH (p2)-[:HAS_TYPE]->(t2:Type)\n",
    "WHERE NOT (p)-[:TRAIN_BOOKING]->(w)\n",
    "    AND p2.capacity <> p.capacity\n",
    "    AND p2.pets_allowed <> p.pets_allowed\n",
    "    AND t2 <> t\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional data sources from feature engineering\n",
    "city_week_pref_attachment = pd.read_csv('Inputs/city_week_pref_attachment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the property to city mapping\n",
    "property_city_mapping = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:LOCATED_IN]->(c:City)\n",
    "RETURN DISTINCT p.id AS property_id, c.name AS city\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the various datasets\n",
    "train_data = pd.concat([train_positive, negative_weeks_ahead, negative_weeks_behind, negative_same_city_diff_attrs], axis = 0)\n",
    "\n",
    "# Expand the property_embedding column into individual columns\n",
    "p_embedding_cols = [f\"property_embedding___{i + 1}\" for i in range(len(train_data.iloc[0].property_embedding))]\n",
    "train_data[p_embedding_cols] = train_data['property_embedding'].apply(pd.Series)\n",
    "train_data.drop(columns = ['property_embedding'], inplace = True)\n",
    "train_data = train_data.drop_duplicates()\n",
    "\n",
    "# Merge in the city_week_pref_attachment data\n",
    "train_data = (\n",
    "    train_data\n",
    "    .merge(property_city_mapping, on = 'property_id', how = 'left')\n",
    "    .merge(city_week_pref_attachment, how = 'left', on = ['city', 'week_num'])\n",
    "    .drop(columns = 'city') # This is included in the embedding, so we don't need it twice\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21380, 71)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>week_num</th>\n",
       "      <th>week_degree</th>\n",
       "      <th>capacity</th>\n",
       "      <th>pets_allowed</th>\n",
       "      <th>is_booked</th>\n",
       "      <th>property_embedding___1</th>\n",
       "      <th>property_embedding___2</th>\n",
       "      <th>property_embedding___3</th>\n",
       "      <th>property_embedding___4</th>\n",
       "      <th>...</th>\n",
       "      <th>property_embedding___56</th>\n",
       "      <th>property_embedding___57</th>\n",
       "      <th>property_embedding___58</th>\n",
       "      <th>property_embedding___59</th>\n",
       "      <th>property_embedding___60</th>\n",
       "      <th>property_embedding___61</th>\n",
       "      <th>property_embedding___62</th>\n",
       "      <th>property_embedding___63</th>\n",
       "      <th>property_embedding___64</th>\n",
       "      <th>city_week_pref_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>683</td>\n",
       "      <td>31</td>\n",
       "      <td>982.0</td>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>354798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>938</td>\n",
       "      <td>31</td>\n",
       "      <td>982.0</td>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208514</td>\n",
       "      <td>0.208514</td>\n",
       "      <td>0.208514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.208514</td>\n",
       "      <td>-0.208514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690</td>\n",
       "      <td>31</td>\n",
       "      <td>982.0</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>185112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>886</td>\n",
       "      <td>31</td>\n",
       "      <td>982.0</td>\n",
       "      <td>8</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>354798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>31</td>\n",
       "      <td>982.0</td>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>365082.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_id  week_num  week_degree  capacity pets_allowed  is_booked  \\\n",
       "0          683        31        982.0         5          yes          1   \n",
       "1          938        31        982.0         5          yes          1   \n",
       "2          690        31        982.0         4           no          1   \n",
       "3          886        31        982.0         8          yes          1   \n",
       "4          221        31        982.0         5          yes          1   \n",
       "\n",
       "   property_embedding___1  property_embedding___2  property_embedding___3  \\\n",
       "0                     0.0                0.000000                0.000000   \n",
       "1                     0.0                0.208514                0.208514   \n",
       "2                     0.0                0.000000                0.000000   \n",
       "3                     0.0                0.000000                0.000000   \n",
       "4                     0.0                0.000000                0.000000   \n",
       "\n",
       "   property_embedding___4  ...  property_embedding___56  \\\n",
       "0                0.000000  ...                 0.223607   \n",
       "1                0.208514  ...                 0.000000   \n",
       "2                0.223607  ...                 0.000000   \n",
       "3                0.000000  ...                 0.223607   \n",
       "4                0.000000  ...                 0.223607   \n",
       "\n",
       "   property_embedding___57  property_embedding___58  property_embedding___59  \\\n",
       "0                -0.223607                 0.000000                -0.223607   \n",
       "1                -0.208514                -0.208514                 0.000000   \n",
       "2                 0.000000                 0.000000                 0.000000   \n",
       "3                -0.223607                 0.000000                -0.223607   \n",
       "4                -0.223607                 0.000000                -0.223607   \n",
       "\n",
       "   property_embedding___60  property_embedding___61  property_embedding___62  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   property_embedding___63  property_embedding___64  city_week_pref_attachment  \n",
       "0                 0.000000                -0.223607                   354798.0  \n",
       "1                 0.000000                 0.000000                   203109.0  \n",
       "2                -0.223607                 0.223607                   185112.0  \n",
       "3                 0.000000                -0.223607                   354798.0  \n",
       "4                 0.000000                -0.223607                   365082.0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same thing for the test data\n",
    "should functionize this to minimize code duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positive = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:HOLDOUT_BOOKING]->(w:Week)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   1 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all properties that had did not have a booking in the current week, but had a booking in at least one of the previous two weeks\n",
    "test_negative_weeks_ahead = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:HOLDOUT_BOOKING]->()\n",
    "MATCH (p)-[:HOLDOUT_BOOKING]->(:Week)-[:PRECEDES*1..4]->(w)\n",
    "WHERE NOT (p)-[:HOLDOUT_BOOKING]->(w)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch the order of the relationship in the second match\n",
    "test_negative_weeks_behind = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:HOLDOUT_BOOKING]->()\n",
    "MATCH (p)-[:HOLDOUT_BOOKING]->(:Week)<-[:PRECEDES*1..4]-(w)\n",
    "WHERE NOT (p)-[:HOLDOUT_BOOKING]->(w)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties that were not booked on a given week where a totally different property was booked that week in the same city\n",
    "test_negative_same_city_diff_attrs = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:LOCATED_IN]->(c:City)\n",
    "MATCH (p)-[:HAS_TYPE]->(t:Type)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:HOLDOUT_BOOKING]->()\n",
    "MATCH (c)<-[:LOCATED_IN]-(p2:Property)-[:HOLDOUT_BOOKING]->(w)\n",
    "MATCH (p2)-[:HAS_TYPE]->(t2:Type)\n",
    "WHERE NOT (p)-[:HOLDOUT_BOOKING]->(w)\n",
    "    AND p2.capacity <> p.capacity\n",
    "    AND p2.pets_allowed <> p.pets_allowed\n",
    "    AND t2 <> t\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the various datasets\n",
    "test_data = pd.concat([test_positive, test_negative_weeks_ahead, test_negative_weeks_behind, test_negative_same_city_diff_attrs], axis = 0)\n",
    "\n",
    "# Expand the property_embedding column into individual columns\n",
    "p_embedding_cols = [f\"property_embedding___{i + 1}\" for i in range(len(test_data.iloc[0].property_embedding))]\n",
    "test_data[p_embedding_cols] = test_data['property_embedding'].apply(pd.Series)\n",
    "test_data.drop(columns = ['property_embedding'], inplace = True)\n",
    "test_data = test_data.drop_duplicates()\n",
    "\n",
    "# Merge in the city_week_pref_attachment data\n",
    "test_data = (\n",
    "    test_data\n",
    "    .merge(property_city_mapping, on = 'property_id', how = 'left')\n",
    "    .merge(city_week_pref_attachment, how = 'left', on = ['city', 'week_num'])\n",
    "    .drop(columns = 'city') # This is included in the embedding, so we don't need it twice\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_booked\n",
       "0    10981\n",
       "1     9266\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.value_counts('is_booked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns = ['is_booked', 'property_id'])\n",
    "y_train = train_data['is_booked']\n",
    "\n",
    "X_test = test_data.drop(columns = ['is_booked', 'property_id'])\n",
    "y_test = test_data['is_booked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 08-29 02:28:42] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 08-29 02:28:42] {1691} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 08-29 02:28:42] {1789} INFO - Minimizing error metric: 1-f1\n",
      "[flaml.automl.logger: 08-29 02:28:42] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 08-29 02:28:42] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:42] {2345} INFO - Estimated sufficient time budget=652s. Estimated necessary time budget=4s.\n",
      "[flaml.automl.logger: 08-29 02:28:42] {2392} INFO -  at 0.3s,\testimator lgbm's best error=0.2246,\tbest estimator lgbm's best error=0.2246\n",
      "[flaml.automl.logger: 08-29 02:28:42] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:42] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.2246,\tbest estimator lgbm's best error=0.2246\n",
      "[flaml.automl.logger: 08-29 02:28:42] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:42] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.2246,\tbest estimator lgbm's best error=0.2246\n",
      "[flaml.automl.logger: 08-29 02:28:42] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2392} INFO -  at 0.6s,\testimator lgbm's best error=0.2242,\tbest estimator lgbm's best error=0.2242\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.2220,\tbest estimator lgbm's best error=0.2220\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.2220,\tbest estimator lgbm's best error=0.2220\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.2220,\tbest estimator lgbm's best error=0.2220\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2392} INFO -  at 1.3s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2392} INFO -  at 1.5s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:43] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:44] {2392} INFO -  at 2.6s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:44] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:45] {2392} INFO -  at 3.0s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:45] {2219} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:45] {2392} INFO -  at 3.3s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:45] {2219} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:46] {2392} INFO -  at 3.9s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:46] {2219} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:46] {2392} INFO -  at 4.1s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:46] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:46] {2392} INFO -  at 4.4s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:46] {2219} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:47] {2392} INFO -  at 4.8s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:47] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:47] {2392} INFO -  at 5.1s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:47] {2219} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2392} INFO -  at 5.6s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2219} INFO - iteration 18, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2392} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2219} INFO - iteration 19, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2392} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2219} INFO - iteration 20, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2392} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2219} INFO - iteration 21, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2392} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2219} INFO - iteration 22, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2392} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2219} INFO - iteration 23, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2392} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2219} INFO - iteration 24, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2392} INFO -  at 6.6s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:48] {2219} INFO - iteration 25, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:49] {2392} INFO -  at 6.7s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:49] {2219} INFO - iteration 26, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:49] {2392} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.2385,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:49] {2219} INFO - iteration 27, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:49] {2392} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.2368,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:49] {2219} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:49] {2392} INFO -  at 7.1s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:49] {2219} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:50] {2392} INFO -  at 7.8s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:50] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:50] {2392} INFO -  at 8.4s,\testimator lgbm's best error=0.2194,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:50] {2219} INFO - iteration 31, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:50] {2392} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.2368,\tbest estimator lgbm's best error=0.2194\n",
      "[flaml.automl.logger: 08-29 02:28:50] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2392} INFO -  at 8.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2219} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2392} INFO -  at 9.0s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2219} INFO - iteration 34, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2392} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2219} INFO - iteration 35, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2392} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2219} INFO - iteration 36, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2392} INFO -  at 9.3s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2219} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2392} INFO -  at 9.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:51] {2219} INFO - iteration 38, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2392} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2219} INFO - iteration 39, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2392} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2219} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2392} INFO -  at 9.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2219} INFO - iteration 41, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2392} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2219} INFO - iteration 42, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2392} INFO -  at 10.1s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2219} INFO - iteration 43, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2392} INFO -  at 10.2s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2219} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2392} INFO -  at 10.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2219} INFO - iteration 45, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2392} INFO -  at 10.5s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:52] {2219} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:53] {2392} INFO -  at 11.0s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:53] {2219} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:53] {2392} INFO -  at 11.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:53] {2219} INFO - iteration 48, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:53] {2392} INFO -  at 11.2s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:53] {2219} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:53] {2392} INFO -  at 11.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:53] {2219} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2392} INFO -  at 11.7s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2219} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2392} INFO -  at 11.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2219} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2392} INFO -  at 12.2s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2219} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2392} INFO -  at 12.3s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2219} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2392} INFO -  at 12.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:54] {2219} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:55] {2392} INFO -  at 12.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:55] {2219} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:55] {2392} INFO -  at 13.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:55] {2219} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:56] {2392} INFO -  at 13.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:56] {2219} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:56] {2392} INFO -  at 14.0s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:56] {2219} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:56] {2392} INFO -  at 14.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:56] {2219} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:56] {2392} INFO -  at 14.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:56] {2219} INFO - iteration 61, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:57] {2392} INFO -  at 14.6s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:57] {2219} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:57] {2392} INFO -  at 14.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:57] {2219} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:57] {2392} INFO -  at 14.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:57] {2219} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:57] {2392} INFO -  at 14.9s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:57] {2219} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:58] {2392} INFO -  at 15.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:58] {2219} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:58] {2392} INFO -  at 15.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:58] {2219} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:58] {2392} INFO -  at 16.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:58] {2219} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:58] {2392} INFO -  at 16.2s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:58] {2219} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:59] {2392} INFO -  at 16.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:59] {2219} INFO - iteration 70, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:59] {2392} INFO -  at 17.0s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:59] {2219} INFO - iteration 71, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:28:59] {2392} INFO -  at 17.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:59] {2219} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:28:59] {2392} INFO -  at 17.2s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:28:59] {2219} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:00] {2392} INFO -  at 18.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:00] {2219} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:00] {2392} INFO -  at 18.2s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:00] {2219} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:00] {2392} INFO -  at 18.4s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:00] {2219} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:01] {2392} INFO -  at 19.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:01] {2219} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:02] {2392} INFO -  at 20.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:02] {2219} INFO - iteration 78, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:02] {2392} INFO -  at 20.5s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:02] {2219} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:02] {2392} INFO -  at 20.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:02] {2219} INFO - iteration 80, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:03] {2392} INFO -  at 20.7s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:03] {2219} INFO - iteration 81, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:03] {2392} INFO -  at 20.8s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:03] {2219} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:03] {2392} INFO -  at 21.0s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:03] {2219} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2392} INFO -  at 21.7s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2219} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2392} INFO -  at 21.8s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2219} INFO - iteration 85, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2392} INFO -  at 21.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2219} INFO - iteration 86, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2392} INFO -  at 22.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2219} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2392} INFO -  at 22.5s,\testimator xgb_limitdepth's best error=0.2334,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:04] {2219} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2392} INFO -  at 22.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2219} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2392} INFO -  at 22.7s,\testimator xgb_limitdepth's best error=0.2265,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2219} INFO - iteration 90, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2392} INFO -  at 22.8s,\testimator xgb_limitdepth's best error=0.2265,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2219} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2392} INFO -  at 23.3s,\testimator xgb_limitdepth's best error=0.2265,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2219} INFO - iteration 92, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2392} INFO -  at 23.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2219} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2392} INFO -  at 23.5s,\testimator xgb_limitdepth's best error=0.2238,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:05] {2219} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 23.6s,\testimator xgb_limitdepth's best error=0.2238,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 23.7s,\testimator xgb_limitdepth's best error=0.2238,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 96, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 23.8s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 23.9s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 24.0s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 24.1s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 24.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 101, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 24.5s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2392} INFO -  at 24.6s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:06] {2219} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2392} INFO -  at 24.7s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2219} INFO - iteration 104, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2392} INFO -  at 24.8s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2219} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2392} INFO -  at 24.9s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2219} INFO - iteration 106, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2392} INFO -  at 25.0s,\testimator xgb_limitdepth's best error=0.2210,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2219} INFO - iteration 107, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2392} INFO -  at 25.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2219} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2392} INFO -  at 25.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2219} INFO - iteration 109, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2392} INFO -  at 25.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:07] {2219} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2392} INFO -  at 25.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2219} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2392} INFO -  at 25.8s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2219} INFO - iteration 112, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2392} INFO -  at 26.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2219} INFO - iteration 113, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2392} INFO -  at 26.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2219} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2392} INFO -  at 26.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:08] {2219} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:09] {2392} INFO -  at 26.8s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:09] {2219} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:09] {2392} INFO -  at 27.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:09] {2219} INFO - iteration 117, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2392} INFO -  at 27.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2219} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2392} INFO -  at 28.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2219} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2392} INFO -  at 28.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2219} INFO - iteration 120, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2392} INFO -  at 28.3s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2219} INFO - iteration 121, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2392} INFO -  at 28.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:10] {2219} INFO - iteration 122, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:11] {2392} INFO -  at 28.7s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:11] {2219} INFO - iteration 123, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:11] {2392} INFO -  at 28.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:11] {2219} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:11] {2392} INFO -  at 29.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:11] {2219} INFO - iteration 125, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:11] {2392} INFO -  at 29.5s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:11] {2219} INFO - iteration 126, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:12] {2392} INFO -  at 30.0s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:12] {2219} INFO - iteration 127, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:12] {2392} INFO -  at 30.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:12] {2219} INFO - iteration 128, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:12] {2392} INFO -  at 30.3s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:12] {2219} INFO - iteration 129, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:12] {2392} INFO -  at 30.5s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:12] {2219} INFO - iteration 130, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:13] {2392} INFO -  at 30.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:13] {2219} INFO - iteration 131, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:13] {2392} INFO -  at 30.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:13] {2219} INFO - iteration 132, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:13] {2392} INFO -  at 30.9s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:13] {2219} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:13] {2392} INFO -  at 31.5s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:13] {2219} INFO - iteration 134, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:14] {2392} INFO -  at 31.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:14] {2219} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:14] {2392} INFO -  at 31.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:14] {2219} INFO - iteration 136, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:14] {2392} INFO -  at 32.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:14] {2219} INFO - iteration 137, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:15] {2392} INFO -  at 33.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:15] {2219} INFO - iteration 138, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:15] {2392} INFO -  at 33.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:15] {2219} INFO - iteration 139, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2392} INFO -  at 33.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2219} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2392} INFO -  at 33.9s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2219} INFO - iteration 141, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2392} INFO -  at 34.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2219} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2392} INFO -  at 34.3s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2219} INFO - iteration 143, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2392} INFO -  at 34.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:16] {2219} INFO - iteration 144, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:17] {2392} INFO -  at 34.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:17] {2219} INFO - iteration 145, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:17] {2392} INFO -  at 34.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:17] {2219} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:17] {2392} INFO -  at 34.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:17] {2219} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:17] {2392} INFO -  at 35.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:17] {2219} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:18] {2392} INFO -  at 36.2s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:18] {2219} INFO - iteration 149, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:18] {2392} INFO -  at 36.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:18] {2219} INFO - iteration 150, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2392} INFO -  at 36.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2219} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2392} INFO -  at 36.7s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2219} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2392} INFO -  at 36.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2219} INFO - iteration 153, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2392} INFO -  at 36.9s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2219} INFO - iteration 154, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2392} INFO -  at 37.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:19] {2219} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:20] {2392} INFO -  at 38.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:20] {2219} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2392} INFO -  at 38.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2219} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2392} INFO -  at 38.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2219} INFO - iteration 158, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2392} INFO -  at 38.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2219} INFO - iteration 159, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2392} INFO -  at 39.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2219} INFO - iteration 160, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2392} INFO -  at 39.3s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2219} INFO - iteration 161, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2392} INFO -  at 39.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:21] {2219} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:22] {2392} INFO -  at 40.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:22] {2219} INFO - iteration 163, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2392} INFO -  at 40.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2219} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2392} INFO -  at 41.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2219} INFO - iteration 165, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2392} INFO -  at 41.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2219} INFO - iteration 166, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2392} INFO -  at 41.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2219} INFO - iteration 167, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2392} INFO -  at 41.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:23] {2219} INFO - iteration 168, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2392} INFO -  at 41.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2219} INFO - iteration 169, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2392} INFO -  at 42.0s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2219} INFO - iteration 170, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2392} INFO -  at 42.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2219} INFO - iteration 171, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2392} INFO -  at 42.5s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2219} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2392} INFO -  at 42.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:24] {2219} INFO - iteration 173, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:25] {2392} INFO -  at 42.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:25] {2219} INFO - iteration 174, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:25] {2392} INFO -  at 43.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:25] {2219} INFO - iteration 175, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:25] {2392} INFO -  at 43.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:25] {2219} INFO - iteration 176, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2392} INFO -  at 43.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2219} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2392} INFO -  at 43.8s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2219} INFO - iteration 178, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2392} INFO -  at 44.0s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2219} INFO - iteration 179, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2392} INFO -  at 44.2s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2219} INFO - iteration 180, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2392} INFO -  at 44.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:26] {2219} INFO - iteration 181, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2392} INFO -  at 44.7s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2219} INFO - iteration 182, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2392} INFO -  at 44.8s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2219} INFO - iteration 183, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2392} INFO -  at 45.0s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2219} INFO - iteration 184, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2392} INFO -  at 45.3s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2219} INFO - iteration 185, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2392} INFO -  at 45.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:27] {2219} INFO - iteration 186, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:28] {2392} INFO -  at 45.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:28] {2219} INFO - iteration 187, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:28] {2392} INFO -  at 46.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:28] {2219} INFO - iteration 188, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:28] {2392} INFO -  at 46.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:28] {2219} INFO - iteration 189, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:29] {2392} INFO -  at 46.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:29] {2219} INFO - iteration 190, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:29] {2392} INFO -  at 46.8s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:29] {2219} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:29] {2392} INFO -  at 47.0s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:29] {2219} INFO - iteration 192, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:30] {2392} INFO -  at 47.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:30] {2219} INFO - iteration 193, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:30] {2392} INFO -  at 48.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:30] {2219} INFO - iteration 194, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2392} INFO -  at 48.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2219} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2392} INFO -  at 48.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2219} INFO - iteration 196, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2392} INFO -  at 49.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2219} INFO - iteration 197, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2392} INFO -  at 49.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2219} INFO - iteration 198, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2392} INFO -  at 49.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2219} INFO - iteration 199, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2392} INFO -  at 49.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:31] {2219} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2392} INFO -  at 49.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2219} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2392} INFO -  at 49.8s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2219} INFO - iteration 202, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2392} INFO -  at 50.0s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2219} INFO - iteration 203, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2392} INFO -  at 50.3s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2219} INFO - iteration 204, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2392} INFO -  at 50.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:32] {2219} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2392} INFO -  at 50.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2219} INFO - iteration 206, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2392} INFO -  at 50.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2219} INFO - iteration 207, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2392} INFO -  at 51.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2219} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2392} INFO -  at 51.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2219} INFO - iteration 209, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2392} INFO -  at 51.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:33] {2219} INFO - iteration 210, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:34] {2392} INFO -  at 52.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:34] {2219} INFO - iteration 211, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:35] {2392} INFO -  at 53.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:35] {2219} INFO - iteration 212, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:35] {2392} INFO -  at 53.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:35] {2219} INFO - iteration 213, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:35] {2392} INFO -  at 53.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:35] {2219} INFO - iteration 214, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:36] {2392} INFO -  at 53.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:36] {2219} INFO - iteration 215, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:36] {2392} INFO -  at 54.2s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:36] {2219} INFO - iteration 216, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:36] {2392} INFO -  at 54.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:36] {2219} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:36] {2392} INFO -  at 54.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:36] {2219} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:37] {2392} INFO -  at 54.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:37] {2219} INFO - iteration 219, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:37] {2392} INFO -  at 55.3s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:37] {2219} INFO - iteration 220, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:37] {2392} INFO -  at 55.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:37] {2219} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:37] {2392} INFO -  at 55.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:37] {2219} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:38] {2392} INFO -  at 55.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:38] {2219} INFO - iteration 223, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:38] {2392} INFO -  at 56.0s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:38] {2219} INFO - iteration 224, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:38] {2392} INFO -  at 56.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:38] {2219} INFO - iteration 225, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:38] {2392} INFO -  at 56.4s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:38] {2219} INFO - iteration 226, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:39] {2392} INFO -  at 56.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:39] {2219} INFO - iteration 227, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:39] {2392} INFO -  at 56.9s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:39] {2219} INFO - iteration 228, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:39] {2392} INFO -  at 57.5s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:39] {2219} INFO - iteration 229, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:39] {2392} INFO -  at 57.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:39] {2219} INFO - iteration 230, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:40] {2392} INFO -  at 58.1s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:40] {2219} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:40] {2392} INFO -  at 58.2s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:40] {2219} INFO - iteration 232, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:40] {2392} INFO -  at 58.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:40] {2219} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:40] {2392} INFO -  at 58.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:40] {2219} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:41] {2392} INFO -  at 58.7s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:41] {2219} INFO - iteration 235, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:41] {2392} INFO -  at 59.0s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:41] {2219} INFO - iteration 236, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:41] {2392} INFO -  at 59.5s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:41] {2219} INFO - iteration 237, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:41] {2392} INFO -  at 59.6s,\testimator xgb_limitdepth's best error=0.2192,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:41] {2219} INFO - iteration 238, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:42] {2392} INFO -  at 60.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:42] {2219} INFO - iteration 239, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2392} INFO -  at 60.6s,\testimator xgb_limitdepth's best error=0.2191,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2219} INFO - iteration 240, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2392} INFO -  at 60.7s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2219} INFO - iteration 241, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2392} INFO -  at 61.0s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2219} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2392} INFO -  at 61.1s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2219} INFO - iteration 243, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2392} INFO -  at 61.3s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:43] {2219} INFO - iteration 244, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:44] {2392} INFO -  at 61.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:44] {2219} INFO - iteration 245, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:44] {2392} INFO -  at 62.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:44] {2219} INFO - iteration 246, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:44] {2392} INFO -  at 62.5s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:44] {2219} INFO - iteration 247, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2392} INFO -  at 62.8s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2219} INFO - iteration 248, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2392} INFO -  at 62.9s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2219} INFO - iteration 249, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2392} INFO -  at 63.2s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2219} INFO - iteration 250, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2392} INFO -  at 63.4s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2219} INFO - iteration 251, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2392} INFO -  at 63.5s,\testimator xgb_limitdepth's best error=0.2191,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:45] {2219} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:29:46] {2392} INFO -  at 63.6s,\testimator lgbm's best error=0.2180,\tbest estimator lgbm's best error=0.2180\n",
      "[flaml.automl.logger: 08-29 02:29:46] {2219} INFO - iteration 253, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:47] {2392} INFO -  at 65.2s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:29:47] {2219} INFO - iteration 254, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:49] {2392} INFO -  at 66.8s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:29:49] {2219} INFO - iteration 255, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:50] {2392} INFO -  at 68.3s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:29:50] {2219} INFO - iteration 256, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:51] {2392} INFO -  at 69.1s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:29:51] {2219} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:55] {2392} INFO -  at 72.6s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:29:55] {2219} INFO - iteration 258, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:55] {2392} INFO -  at 73.3s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:29:55] {2219} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:29:59] {2392} INFO -  at 76.9s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:29:59] {2219} INFO - iteration 260, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:02] {2392} INFO -  at 79.6s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:02] {2219} INFO - iteration 261, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:02] {2392} INFO -  at 80.6s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:02] {2219} INFO - iteration 262, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:03] {2392} INFO -  at 81.6s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:03] {2219} INFO - iteration 263, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:06] {2392} INFO -  at 84.1s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:06] {2219} INFO - iteration 264, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:13] {2392} INFO -  at 90.7s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:13] {2219} INFO - iteration 265, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:13] {2392} INFO -  at 91.1s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:13] {2219} INFO - iteration 266, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:14] {2392} INFO -  at 91.8s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:14] {2219} INFO - iteration 267, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:17] {2392} INFO -  at 95.5s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:17] {2219} INFO - iteration 268, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:20] {2392} INFO -  at 98.0s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:20] {2219} INFO - iteration 269, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:21] {2392} INFO -  at 99.1s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:21] {2219} INFO - iteration 270, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:23] {2392} INFO -  at 101.2s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:23] {2219} INFO - iteration 271, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:24] {2392} INFO -  at 102.4s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:24] {2219} INFO - iteration 272, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:27] {2392} INFO -  at 104.7s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:27] {2219} INFO - iteration 273, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:30:27] {2392} INFO -  at 105.1s,\testimator lgbm's best error=0.2180,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:27] {2219} INFO - iteration 274, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:28] {2392} INFO -  at 106.2s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:28] {2219} INFO - iteration 275, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:30] {2392} INFO -  at 108.1s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:30] {2219} INFO - iteration 276, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:31] {2392} INFO -  at 109.3s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:31] {2219} INFO - iteration 277, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:32] {2392} INFO -  at 109.7s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:32] {2219} INFO - iteration 278, current learner lgbm\n",
      "[flaml.automl.logger: 08-29 02:30:32] {2392} INFO -  at 109.9s,\testimator lgbm's best error=0.2178,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:32] {2219} INFO - iteration 279, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:38] {2392} INFO -  at 116.5s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:38] {2219} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:39] {2392} INFO -  at 117.4s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:39] {2219} INFO - iteration 281, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 08-29 02:30:42] {2392} INFO -  at 120.0s,\testimator xgb_limitdepth's best error=0.2166,\tbest estimator xgb_limitdepth's best error=0.2166\n",
      "[flaml.automl.logger: 08-29 02:30:44] {2628} INFO - retrain xgb_limitdepth for 1.6s\n",
      "[flaml.automl.logger: 08-29 02:30:44] {2631} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=0.598132805254548, colsample_bynode=None,\n",
      "              colsample_bytree=0.9291439951904144, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.02753608497193262,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=0.259949046439129, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=216,\n",
      "              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-29 02:30:44] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-29 02:30:44] {1932} INFO - Time taken to find the best model: 65.21890950202942\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    \"time_budget\": 120,  # total running time in seconds\n",
    "    \"metric\": 'f1',  # primary metrics can be chosen from: ['accuracy','roc_auc','f1','log_loss']\n",
    "    \"task\": 'classification',  # task type\n",
    "    \"estimator_list\": ['lgbm', 'xgb_limitdepth'],  # list of ML learners\n",
    "}\n",
    "\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_limitdepth\n",
      "{'n_estimators': 216, 'max_depth': 7, 'min_child_weight': 0.259949046439129, 'learning_rate': 0.02753608497193262, 'subsample': 0.8971767792389439, 'colsample_bylevel': 0.598132805254548, 'colsample_bytree': 0.9291439951904144, 'reg_alpha': 80.40768009447709, 'reg_lambda': 173.53435873284334}\n",
      "0.7380729653882133\n",
      "0.6954116659258162\n"
     ]
    }
   ],
   "source": [
    "print(automl.best_estimator)\n",
    "print(automl.best_config)\n",
    "print(automl.score(X_train, y_train, metric='accuracy'))\n",
    "print(automl.score(X_test, y_test, metric='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    pd.DataFrame(zip(automl.feature_names_in_, automl.feature_importances_), columns=['Feature', 'Importance'])\n",
    "    .sort_values('Importance', ascending = False)\n",
    "    .assign(grouped_feature = lambda x: x['Feature'].apply(lambda y: y.split('___')[0]))\n",
    "    .groupby('grouped_feature')['Importance'].sum().sort_values(ascending = True)\n",
    ").plot(kind = 'barh', title = 'Feature Importance Plot')\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Not Booked</th>\n",
       "      <th>Predicted Booked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Not Booked</th>\n",
       "      <td>8653</td>\n",
       "      <td>2328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Booked</th>\n",
       "      <td>3839</td>\n",
       "      <td>5427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Not Booked  Predicted Booked\n",
       "Actual Not Booked                  8653              2328\n",
       "Actual Booked                      3839              5427"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "conf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred), columns = ['Predicted Not Booked', 'Predicted Booked'])\n",
    "conf_mat.index = ['Actual Not Booked', 'Actual Booked']\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6998065764023211, 0.5856896179581265)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred), recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
