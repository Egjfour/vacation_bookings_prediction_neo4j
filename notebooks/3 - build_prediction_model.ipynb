{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience # Load neo4j graph data science library\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if os.getcwd().split('\\\\')[-1] == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Modeling\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a Neo4j instance (assumes local right now)\n",
    "NEO4J_URI = os.environ.get(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_AUTH = None\n",
    "NEO4J_DB = os.environ.get(\"NEO4J_DB\", \"neo4j\")\n",
    "if os.environ.get(\"NEO4J_USER\") and os.environ.get(\"NEO4J_PASSWORD\"):\n",
    "    NEO4J_AUTH = (\n",
    "        os.environ.get(\"NEO4J_USER\"),\n",
    "        os.environ.get(\"NEO4J_PASSWORD\"),\n",
    "    )\n",
    "else:\n",
    "    NEO4J_AUTH = (\"neo4j\", \"Bookings\")\n",
    "gds = GraphDataScience(NEO4J_URI, auth=NEO4J_AUTH, database=NEO4J_DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the training data by finding positive and negative examples of bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:TRAIN_BOOKING]->(w:Week)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   1 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all properties that had did not have a booking in the current week, but had a booking in at least one of the previous two weeks\n",
    "negative_weeks_ahead = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:TRAIN_BOOKING]->()\n",
    "MATCH (p)-[:TRAIN_BOOKING]->(:Week)-[:PRECEDES*1..4]->(w)\n",
    "WHERE NOT (p)-[:TRAIN_BOOKING]->(w)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch the order of the relationship in the second match\n",
    "negative_weeks_behind = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:TRAIN_BOOKING]->()\n",
    "MATCH (p)-[:TRAIN_BOOKING]->(:Week)<-[:PRECEDES*1..4]-(w)\n",
    "WHERE NOT (p)-[:TRAIN_BOOKING]->(w)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties that were not booked on a given week where a totally different property was booked that week in the same city\n",
    "negative_same_city_diff_attrs = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:LOCATED_IN]->(c:City)\n",
    "MATCH (p)-[:HAS_TYPE]->(t:Type)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:TRAIN_BOOKING]->()\n",
    "MATCH (c)<-[:LOCATED_IN]-(p2:Property)-[:TRAIN_BOOKING]->(w)\n",
    "MATCH (p2)-[:HAS_TYPE]->(t2:Type)\n",
    "WHERE NOT (p)-[:TRAIN_BOOKING]->(w)\n",
    "    AND p2.capacity <> p.capacity\n",
    "    AND p2.pets_allowed <> p.pets_allowed\n",
    "    AND t2 <> t\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional data sources from feature engineering\n",
    "city_week_pref_attachment = pd.read_csv('Inputs/city_week_pref_attachment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the property to city mapping\n",
    "property_city_mapping = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:LOCATED_IN]->(c:City)\n",
    "RETURN DISTINCT p.id AS property_id, c.name AS city\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the various datasets\n",
    "train_data = pd.concat([train_positive, negative_weeks_ahead, negative_weeks_behind, negative_same_city_diff_attrs], axis = 0)\n",
    "\n",
    "# Expand the property_embedding column into individual columns\n",
    "p_embedding_cols = [f\"property_embedding___{i + 1}\" for i in range(len(train_data.iloc[0].property_embedding))]\n",
    "train_data[p_embedding_cols] = train_data['property_embedding'].apply(pd.Series)\n",
    "train_data.drop(columns = ['property_embedding'], inplace = True)\n",
    "train_data = train_data.drop_duplicates()\n",
    "\n",
    "# Merge in the city_week_pref_attachment data\n",
    "train_data = (\n",
    "    train_data\n",
    "    .merge(property_city_mapping, on = 'property_id', how = 'left')\n",
    "    .merge(city_week_pref_attachment, how = 'left', on = ['city', 'week_num'])\n",
    "    .drop(columns = 'city') # This is included in the embedding, so we don't need it twice\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21380, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>week_num</th>\n",
       "      <th>week_degree</th>\n",
       "      <th>capacity</th>\n",
       "      <th>pets_allowed</th>\n",
       "      <th>is_booked</th>\n",
       "      <th>property_embedding___1</th>\n",
       "      <th>property_embedding___2</th>\n",
       "      <th>property_embedding___3</th>\n",
       "      <th>property_embedding___4</th>\n",
       "      <th>city_week_pref_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465</td>\n",
       "      <td>41</td>\n",
       "      <td>104.0</td>\n",
       "      <td>9</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.463894</td>\n",
       "      <td>-0.343462</td>\n",
       "      <td>0.118683</td>\n",
       "      <td>-0.090434</td>\n",
       "      <td>27176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978</td>\n",
       "      <td>41</td>\n",
       "      <td>104.0</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805920</td>\n",
       "      <td>-0.937490</td>\n",
       "      <td>-0.004573</td>\n",
       "      <td>-0.631441</td>\n",
       "      <td>24768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>774</td>\n",
       "      <td>41</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074006</td>\n",
       "      <td>-0.699783</td>\n",
       "      <td>0.425849</td>\n",
       "      <td>-1.767583</td>\n",
       "      <td>27176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>41</td>\n",
       "      <td>104.0</td>\n",
       "      <td>6</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.463894</td>\n",
       "      <td>-0.343462</td>\n",
       "      <td>0.118683</td>\n",
       "      <td>-0.090434</td>\n",
       "      <td>27176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203</td>\n",
       "      <td>41</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.377356</td>\n",
       "      <td>-0.296665</td>\n",
       "      <td>-0.184569</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>24768.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_id  week_num  week_degree  capacity pets_allowed  is_booked  \\\n",
       "0          465        41        104.0         9          yes          1   \n",
       "1          978        41        104.0         6           no          1   \n",
       "2          774        41        104.0         8          yes          1   \n",
       "3           79        41        104.0         6          yes          1   \n",
       "4          203        41        104.0         4          yes          1   \n",
       "\n",
       "   property_embedding___1  property_embedding___2  property_embedding___3  \\\n",
       "0                1.463894               -0.343462                0.118683   \n",
       "1                0.805920               -0.937490               -0.004573   \n",
       "2                0.074006               -0.699783                0.425849   \n",
       "3                1.463894               -0.343462                0.118683   \n",
       "4                1.377356               -0.296665               -0.184569   \n",
       "\n",
       "   property_embedding___4  city_week_pref_attachment  \n",
       "0               -0.090434                    27176.0  \n",
       "1               -0.631441                    24768.0  \n",
       "2               -1.767583                    27176.0  \n",
       "3               -0.090434                    27176.0  \n",
       "4                0.632534                    24768.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same thing for the test data\n",
    "should functionize this to minimize code duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positive = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:HOLDOUT_BOOKING]->(w:Week)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   1 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all properties that had did not have a booking in the current week, but had a booking in at least one of the previous two weeks\n",
    "test_negative_weeks_ahead = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:HOLDOUT_BOOKING]->()\n",
    "MATCH (p)-[:HOLDOUT_BOOKING]->(:Week)-[:PRECEDES*1..4]->(w)\n",
    "WHERE NOT (p)-[:HOLDOUT_BOOKING]->(w)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch the order of the relationship in the second match\n",
    "test_negative_weeks_behind = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:HOLDOUT_BOOKING]->()\n",
    "MATCH (p)-[:HOLDOUT_BOOKING]->(:Week)<-[:PRECEDES*1..4]-(w)\n",
    "WHERE NOT (p)-[:HOLDOUT_BOOKING]->(w)\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties that were not booked on a given week where a totally different property was booked that week in the same city\n",
    "test_negative_same_city_diff_attrs = gds.run_cypher(\"\"\"\n",
    "MATCH (p:Property)-[:LOCATED_IN]->(c:City)\n",
    "MATCH (p)-[:HAS_TYPE]->(t:Type)\n",
    "MATCH (w:Week)\n",
    "WHERE (p)-[:HOLDOUT_BOOKING]->()\n",
    "MATCH (c)<-[:LOCATED_IN]-(p2:Property)-[:HOLDOUT_BOOKING]->(w)\n",
    "MATCH (p2)-[:HAS_TYPE]->(t2:Type)\n",
    "WHERE NOT (p)-[:HOLDOUT_BOOKING]->(w)\n",
    "    AND p2.capacity <> p.capacity\n",
    "    AND p2.pets_allowed <> p.pets_allowed\n",
    "    AND t2 <> t\n",
    "RETURN DISTINCT\n",
    "    p.id AS property_id\n",
    ",   w.week_num AS week_num\n",
    ",   w.week_degree AS week_degree\n",
    ",   p.capacity AS capacity\n",
    ",   p.pets_allowed AS pets_allowed\n",
    ",   p.property_embedding AS property_embedding\n",
    ",   0 AS is_booked\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the various datasets\n",
    "test_data = pd.concat([test_positive, test_negative_weeks_ahead, test_negative_weeks_behind, test_negative_same_city_diff_attrs], axis = 0)\n",
    "\n",
    "# Expand the property_embedding column into individual columns\n",
    "p_embedding_cols = [f\"property_embedding___{i + 1}\" for i in range(len(test_data.iloc[0].property_embedding))]\n",
    "test_data[p_embedding_cols] = test_data['property_embedding'].apply(pd.Series)\n",
    "test_data.drop(columns = ['property_embedding'], inplace = True)\n",
    "test_data = test_data.drop_duplicates()\n",
    "\n",
    "# Merge in the city_week_pref_attachment data\n",
    "test_data = (\n",
    "    test_data\n",
    "    .merge(property_city_mapping, on = 'property_id', how = 'left')\n",
    "    .merge(city_week_pref_attachment, how = 'left', on = ['city', 'week_num'])\n",
    "    .drop(columns = 'city') # This is included in the embedding, so we don't need it twice\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_booked\n",
       "0    10981\n",
       "1     9266\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.value_counts('is_booked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns = ['is_booked', 'property_id'])\n",
    "y_train = train_data['is_booked']\n",
    "\n",
    "X_test = test_data.drop(columns = ['is_booked', 'property_id'])\n",
    "y_test = test_data['is_booked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 09-12 20:58:05] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 09-12 20:58:05] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 09-12 20:58:05] {1789} INFO - Minimizing error metric: 1-f1\n",
      "[flaml.automl.logger: 09-12 20:58:05] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 09-12 20:58:05] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:06] {2345} INFO - Estimated sufficient time budget=3507s. Estimated necessary time budget=23s.\n",
      "[flaml.automl.logger: 09-12 20:58:06] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.2344,\tbest estimator lgbm's best error=0.2344\n",
      "[flaml.automl.logger: 09-12 20:58:06] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:06] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.2344,\tbest estimator lgbm's best error=0.2344\n",
      "[flaml.automl.logger: 09-12 20:58:06] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:06] {2392} INFO -  at 1.1s,\testimator lgbm's best error=0.2344,\tbest estimator lgbm's best error=0.2344\n",
      "[flaml.automl.logger: 09-12 20:58:06] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:07] {2392} INFO -  at 1.8s,\testimator lgbm's best error=0.2344,\tbest estimator lgbm's best error=0.2344\n",
      "[flaml.automl.logger: 09-12 20:58:07] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:07] {2392} INFO -  at 2.2s,\testimator lgbm's best error=0.2326,\tbest estimator lgbm's best error=0.2326\n",
      "[flaml.automl.logger: 09-12 20:58:07] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:08] {2392} INFO -  at 2.6s,\testimator lgbm's best error=0.2326,\tbest estimator lgbm's best error=0.2326\n",
      "[flaml.automl.logger: 09-12 20:58:08] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:08] {2392} INFO -  at 3.0s,\testimator lgbm's best error=0.2321,\tbest estimator lgbm's best error=0.2321\n",
      "[flaml.automl.logger: 09-12 20:58:08] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:09] {2392} INFO -  at 3.3s,\testimator lgbm's best error=0.2321,\tbest estimator lgbm's best error=0.2321\n",
      "[flaml.automl.logger: 09-12 20:58:09] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:09] {2392} INFO -  at 4.2s,\testimator lgbm's best error=0.2321,\tbest estimator lgbm's best error=0.2321\n",
      "[flaml.automl.logger: 09-12 20:58:09] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:10] {2392} INFO -  at 4.5s,\testimator lgbm's best error=0.2321,\tbest estimator lgbm's best error=0.2321\n",
      "[flaml.automl.logger: 09-12 20:58:10] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:11] {2392} INFO -  at 5.4s,\testimator lgbm's best error=0.2291,\tbest estimator lgbm's best error=0.2291\n",
      "[flaml.automl.logger: 09-12 20:58:11] {2219} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:12] {2392} INFO -  at 6.5s,\testimator lgbm's best error=0.2291,\tbest estimator lgbm's best error=0.2291\n",
      "[flaml.automl.logger: 09-12 20:58:12] {2219} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:12] {2392} INFO -  at 7.3s,\testimator lgbm's best error=0.2230,\tbest estimator lgbm's best error=0.2230\n",
      "[flaml.automl.logger: 09-12 20:58:12] {2219} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:13] {2392} INFO -  at 8.2s,\testimator lgbm's best error=0.2230,\tbest estimator lgbm's best error=0.2230\n",
      "[flaml.automl.logger: 09-12 20:58:13] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:14] {2392} INFO -  at 8.8s,\testimator lgbm's best error=0.2114,\tbest estimator lgbm's best error=0.2114\n",
      "[flaml.automl.logger: 09-12 20:58:14] {2219} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:14] {2392} INFO -  at 9.3s,\testimator lgbm's best error=0.2114,\tbest estimator lgbm's best error=0.2114\n",
      "[flaml.automl.logger: 09-12 20:58:14] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:15] {2392} INFO -  at 9.8s,\testimator lgbm's best error=0.2114,\tbest estimator lgbm's best error=0.2114\n",
      "[flaml.automl.logger: 09-12 20:58:15] {2219} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:15] {2392} INFO -  at 10.2s,\testimator lgbm's best error=0.2114,\tbest estimator lgbm's best error=0.2114\n",
      "[flaml.automl.logger: 09-12 20:58:15] {2219} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:16] {2392} INFO -  at 10.9s,\testimator lgbm's best error=0.2114,\tbest estimator lgbm's best error=0.2114\n",
      "[flaml.automl.logger: 09-12 20:58:16] {2219} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:16] {2392} INFO -  at 11.3s,\testimator lgbm's best error=0.2114,\tbest estimator lgbm's best error=0.2114\n",
      "[flaml.automl.logger: 09-12 20:58:16] {2219} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:17] {2392} INFO -  at 12.2s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:17] {2219} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:19] {2392} INFO -  at 13.8s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:19] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:20] {2392} INFO -  at 14.4s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:20] {2219} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:21] {2392} INFO -  at 15.6s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:21] {2219} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:22] {2392} INFO -  at 16.4s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:22] {2219} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:22] {2392} INFO -  at 17.1s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:22] {2219} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:24] {2392} INFO -  at 18.4s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:24] {2219} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:25] {2392} INFO -  at 20.2s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:25] {2219} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:26] {2392} INFO -  at 20.7s,\testimator lgbm's best error=0.2108,\tbest estimator lgbm's best error=0.2108\n",
      "[flaml.automl.logger: 09-12 20:58:26] {2219} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:27] {2392} INFO -  at 21.4s,\testimator lgbm's best error=0.2099,\tbest estimator lgbm's best error=0.2099\n",
      "[flaml.automl.logger: 09-12 20:58:27] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:28] {2392} INFO -  at 22.3s,\testimator lgbm's best error=0.2099,\tbest estimator lgbm's best error=0.2099\n",
      "[flaml.automl.logger: 09-12 20:58:28] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:28] {2392} INFO -  at 22.8s,\testimator lgbm's best error=0.2099,\tbest estimator lgbm's best error=0.2099\n",
      "[flaml.automl.logger: 09-12 20:58:28] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:29] {2392} INFO -  at 24.1s,\testimator lgbm's best error=0.2099,\tbest estimator lgbm's best error=0.2099\n",
      "[flaml.automl.logger: 09-12 20:58:29] {2219} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:30] {2392} INFO -  at 24.5s,\testimator lgbm's best error=0.2099,\tbest estimator lgbm's best error=0.2099\n",
      "[flaml.automl.logger: 09-12 20:58:30] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:31] {2392} INFO -  at 25.4s,\testimator lgbm's best error=0.2099,\tbest estimator lgbm's best error=0.2099\n",
      "[flaml.automl.logger: 09-12 20:58:31] {2219} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:34] {2392} INFO -  at 28.5s,\testimator lgbm's best error=0.2099,\tbest estimator lgbm's best error=0.2099\n",
      "[flaml.automl.logger: 09-12 20:58:34] {2219} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:34] {2392} INFO -  at 28.9s,\testimator lgbm's best error=0.2099,\tbest estimator lgbm's best error=0.2099\n",
      "[flaml.automl.logger: 09-12 20:58:34] {2219} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:35] {2392} INFO -  at 30.1s,\testimator lgbm's best error=0.2091,\tbest estimator lgbm's best error=0.2091\n",
      "[flaml.automl.logger: 09-12 20:58:35] {2219} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:36] {2392} INFO -  at 30.8s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:36] {2219} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:38] {2392} INFO -  at 32.9s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:38] {2219} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:38] {2392} INFO -  at 33.2s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:38] {2219} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:39] {2392} INFO -  at 33.6s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:39] {2219} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:41] {2392} INFO -  at 36.2s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:41] {2219} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:43] {2392} INFO -  at 37.6s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:43] {2219} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:43] {2392} INFO -  at 38.0s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:43] {2219} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:44] {2392} INFO -  at 38.5s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:44] {2219} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:46] {2392} INFO -  at 41.1s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:46] {2219} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:47] {2392} INFO -  at 41.4s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:47] {2219} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:51] {2392} INFO -  at 45.4s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:51] {2219} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:51] {2392} INFO -  at 46.0s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:51] {2219} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:58:56] {2392} INFO -  at 50.7s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:58:56] {2219} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:00] {2392} INFO -  at 54.6s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:59:00] {2219} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 09-12 20:59:01] {2392} INFO -  at 55.3s,\testimator xgb_limitdepth's best error=0.2496,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:59:01] {2219} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 09-12 20:59:01] {2392} INFO -  at 56.0s,\testimator xgb_limitdepth's best error=0.2460,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:59:01] {2219} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:02] {2392} INFO -  at 56.5s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:59:02] {2219} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:04] {2392} INFO -  at 59.2s,\testimator lgbm's best error=0.2088,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:59:04] {2219} INFO - iteration 56, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 09-12 20:59:05] {2392} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.2460,\tbest estimator lgbm's best error=0.2088\n",
      "[flaml.automl.logger: 09-12 20:59:05] {2219} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:06] {2392} INFO -  at 60.4s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:06] {2219} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 09-12 20:59:06] {2392} INFO -  at 61.2s,\testimator xgb_limitdepth's best error=0.2460,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:06] {2219} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:07] {2392} INFO -  at 62.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:07] {2219} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:08] {2392} INFO -  at 62.8s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:08] {2219} INFO - iteration 61, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 09-12 20:59:09] {2392} INFO -  at 63.6s,\testimator xgb_limitdepth's best error=0.2397,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:09] {2219} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:09] {2392} INFO -  at 64.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:09] {2219} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:10] {2392} INFO -  at 64.6s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:10] {2219} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 09-12 20:59:10] {2392} INFO -  at 65.0s,\testimator xgb_limitdepth's best error=0.2397,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:10] {2219} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:11] {2392} INFO -  at 65.4s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:11] {2219} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:11] {2392} INFO -  at 66.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:11] {2219} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:13] {2392} INFO -  at 67.5s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:13] {2219} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:13] {2392} INFO -  at 67.9s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:13] {2219} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:14] {2392} INFO -  at 68.3s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:14] {2219} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:14] {2392} INFO -  at 68.7s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:14] {2219} INFO - iteration 71, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:14] {2392} INFO -  at 69.3s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:14] {2219} INFO - iteration 72, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:15] {2392} INFO -  at 69.7s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:15] {2219} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:15] {2392} INFO -  at 70.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:15] {2219} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:16] {2392} INFO -  at 70.6s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:16] {2219} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:17] {2392} INFO -  at 72.2s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:17] {2219} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:18] {2392} INFO -  at 72.6s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:18] {2219} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:18] {2392} INFO -  at 73.0s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:18] {2219} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:19] {2392} INFO -  at 73.4s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:19] {2219} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:19] {2392} INFO -  at 73.8s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:19] {2219} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:20] {2392} INFO -  at 75.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:20] {2219} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:21] {2392} INFO -  at 76.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:21] {2219} INFO - iteration 82, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:22] {2392} INFO -  at 76.4s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:22] {2219} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:22] {2392} INFO -  at 76.9s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:22] {2219} INFO - iteration 84, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:23] {2392} INFO -  at 78.0s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:23] {2219} INFO - iteration 85, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:24] {2392} INFO -  at 78.8s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:24] {2219} INFO - iteration 86, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:24] {2392} INFO -  at 79.2s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:24] {2219} INFO - iteration 87, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:26] {2392} INFO -  at 80.7s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:26] {2219} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:26] {2392} INFO -  at 81.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:26] {2219} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 09-12 20:59:27] {2392} INFO -  at 81.9s,\testimator xgb_limitdepth's best error=0.2397,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:27] {2219} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:27] {2392} INFO -  at 82.3s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:27] {2219} INFO - iteration 91, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:28] {2392} INFO -  at 82.8s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:28] {2219} INFO - iteration 92, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:28] {2392} INFO -  at 83.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:28] {2219} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:29] {2392} INFO -  at 83.8s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:29] {2219} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:29] {2392} INFO -  at 84.2s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:29] {2219} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:30] {2392} INFO -  at 84.7s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:30] {2219} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:30] {2392} INFO -  at 85.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:30] {2219} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:31] {2392} INFO -  at 85.5s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:31] {2219} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:31] {2392} INFO -  at 86.0s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:31] {2219} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:32] {2392} INFO -  at 86.7s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:32] {2219} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:32] {2392} INFO -  at 87.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:32] {2219} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:33] {2392} INFO -  at 88.3s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:33] {2219} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:34] {2392} INFO -  at 88.9s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:34] {2219} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:34] {2392} INFO -  at 89.2s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:34] {2219} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:35] {2392} INFO -  at 89.6s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:35] {2219} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:35] {2392} INFO -  at 90.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:35] {2219} INFO - iteration 106, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:36] {2392} INFO -  at 90.5s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:36] {2219} INFO - iteration 107, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:36] {2392} INFO -  at 91.0s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:36] {2219} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:37] {2392} INFO -  at 92.1s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:37] {2219} INFO - iteration 109, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:38] {2392} INFO -  at 92.5s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:38] {2219} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:39] {2392} INFO -  at 93.4s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:39] {2219} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 09-12 20:59:39] {2392} INFO -  at 94.0s,\testimator xgb_limitdepth's best error=0.2397,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:39] {2219} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:40] {2392} INFO -  at 94.4s,\testimator lgbm's best error=0.2086,\tbest estimator lgbm's best error=0.2086\n",
      "[flaml.automl.logger: 09-12 20:59:40] {2219} INFO - iteration 113, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:40] {2392} INFO -  at 94.9s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:40] {2219} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:41] {2392} INFO -  at 95.3s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:41] {2219} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:41] {2392} INFO -  at 95.7s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:41] {2219} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:42] {2392} INFO -  at 97.0s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:42] {2219} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:43] {2392} INFO -  at 97.5s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:43] {2219} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:43] {2392} INFO -  at 98.1s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:43] {2219} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:45] {2392} INFO -  at 99.8s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:45] {2219} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:45] {2392} INFO -  at 100.2s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:45] {2219} INFO - iteration 121, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:46] {2392} INFO -  at 100.9s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:46] {2219} INFO - iteration 122, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:47] {2392} INFO -  at 101.5s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:47] {2219} INFO - iteration 123, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:47] {2392} INFO -  at 102.0s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:47] {2219} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:48] {2392} INFO -  at 103.2s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:48] {2219} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:51] {2392} INFO -  at 105.4s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:51] {2219} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:51] {2392} INFO -  at 105.9s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:51] {2219} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:52] {2392} INFO -  at 106.7s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:52] {2219} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:52] {2392} INFO -  at 107.2s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:52] {2219} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:53] {2392} INFO -  at 107.8s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:53] {2219} INFO - iteration 130, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:54] {2392} INFO -  at 108.3s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:54] {2219} INFO - iteration 131, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:54] {2392} INFO -  at 109.0s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:54] {2219} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:55] {2392} INFO -  at 110.0s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:55] {2219} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:56] {2392} INFO -  at 110.7s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:56] {2219} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:56] {2392} INFO -  at 111.1s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:56] {2219} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 20:59:59] {2392} INFO -  at 114.2s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 20:59:59] {2219} INFO - iteration 136, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 21:00:00] {2392} INFO -  at 114.8s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 21:00:00] {2219} INFO - iteration 137, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 21:00:01] {2392} INFO -  at 115.5s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 21:00:01] {2219} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 21:00:01] {2392} INFO -  at 115.9s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 21:00:01] {2219} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 21:00:02] {2392} INFO -  at 116.3s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 21:00:02] {2219} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 21:00:03] {2392} INFO -  at 117.4s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 21:00:03] {2219} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl.logger: 09-12 21:00:05] {2392} INFO -  at 119.8s,\testimator lgbm's best error=0.2083,\tbest estimator lgbm's best error=0.2083\n",
      "[flaml.automl.logger: 09-12 21:00:05] {2628} INFO - retrain lgbm for 0.2s\n",
      "[flaml.automl.logger: 09-12 21:00:05] {2631} INFO - retrained model: LGBMClassifier(colsample_bytree=0.697033093803828,\n",
      "               learning_rate=0.002060722469131402, max_bin=63,\n",
      "               min_child_samples=40, n_estimators=1, n_jobs=-1, num_leaves=136,\n",
      "               reg_alpha=0.0030731834287241445, reg_lambda=11.083985780534016,\n",
      "               verbose=-1)\n",
      "[flaml.automl.logger: 09-12 21:00:05] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 09-12 21:00:05] {1932} INFO - Time taken to find the best model: 94.91342353820801\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    \"time_budget\": 120,  # total running time in seconds\n",
    "    \"metric\": 'f1',  # primary metrics can be chosen from: ['accuracy','roc_auc','f1','log_loss']\n",
    "    \"task\": 'classification',  # task type\n",
    "    \"estimator_list\": ['lgbm', 'xgb_limitdepth'],  # list of ML learners\n",
    "}\n",
    "\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm\n",
      "{'n_estimators': 5, 'num_leaves': 136, 'min_child_samples': 40, 'learning_rate': 0.002060722469131402, 'log_max_bin': 6, 'colsample_bytree': 0.697033093803828, 'reg_alpha': 0.0030731834287241445, 'reg_lambda': 11.083985780534016}\n",
      "0.7365762394761459\n",
      "0.6613819331258952\n"
     ]
    }
   ],
   "source": [
    "print(automl.best_estimator)\n",
    "print(automl.best_config)\n",
    "print(automl.score(X_train, y_train, metric='accuracy'))\n",
    "print(automl.score(X_test, y_test, metric='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    pd.DataFrame(zip(automl.feature_names_in_, automl.feature_importances_), columns=['Feature', 'Importance'])\n",
    "    .sort_values('Importance', ascending = False)\n",
    "    .assign(grouped_feature = lambda x: x['Feature'].apply(lambda y: y.split('___')[0]))\n",
    "    .groupby('grouped_feature')['Importance'].sum().sort_values(ascending = True)\n",
    ").plot(kind = 'barh', title = 'Feature Importance Plot')\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Not Booked</th>\n",
       "      <th>Predicted Booked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Not Booked</th>\n",
       "      <td>4199</td>\n",
       "      <td>6782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Booked</th>\n",
       "      <td>74</td>\n",
       "      <td>9192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Not Booked  Predicted Booked\n",
       "Actual Not Booked                  4199              6782\n",
       "Actual Booked                        74              9192"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "conf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred), columns = ['Predicted Not Booked', 'Predicted Booked'])\n",
    "conf_mat.index = ['Actual Not Booked', 'Actual Booked']\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5754350820082634, 0.9920138139434491)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "precision_score(y_test, y_pred), recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
